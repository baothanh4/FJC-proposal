[
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Tào Bảo Thành\nSố điện thoại: 0901452366\nEmail: taobaothanh365@gmail.com\nTrường: Đại học FPT Hồ Chí Minh\nNgành: Kỹ Thuật Phần Mềm\nLớp: OJT202\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Báo cáo Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 8 (Week 8 Objectives): Hiểu các khái niệm cơ bản và trường hợp sử dụng của AWS Step Functions, bao gồm 7 loại trạng thái chính và cách phối hợp các bước để điều phối các quy trình phức tạp.\nThực hành tạo và kiểm thử workflow trong AWS Cloud9, tập trung vào việc điều phối tác vụ (task orchestration) và xử lý lỗi (error handling).\nTìm hiểu các tính năng chính và các bước triển khai của Amazon FSx, bao gồm các biến thể khác nhau: FSx for Windows File Server, FSx for Lustre, FSx for NetApp ONTAP, và FSx for OpenZFS.\nThực hành cấu hình hệ thống tệp FSx tích hợp với AWS Managed Microsoft AD, đảm bảo thiết lập đúng về mạng, xác thực và chia sẻ tệp (file sharing).\nKhám phá AWS X-Ray để hiểu cách theo dõi và trực quan hóa các yêu cầu trong ứng dụng phân tán nhằm tối ưu hóa hiệu năng và xử lý lỗi.\nNhiệm vụ thực hiện trong tuần (Tasks to be carried out this week): Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học về AWS Step Functions: + 7 trạng thái: Task state, Choice state, Fail/Success state, Pass state, Wait state, Parallel state, Map state + Các trường hợp sử dụng Step Functions + Lợi ích của AWS Step Functions 26/10/2025 27/10/2025 https://000047.awsstudygroup.com/1-intro/ 3 - Thực hành: + Tạo môi trường Cloud9 + Tạo các dịch vụ mẫu + Khởi tạo workflow + Xử lý lỗi 27/10/2025 28/10/2025 https://000047.awsstudygroup.com/1-intro/ 4 - Học về Amazon FSx: + FSx for Windows File Server + FSx for Lustre + FSx for NetApp ONTAP + FSx for OpenZFS 28/10/2025 29/10/2025 https://000025.awsstudygroup.com/ 5 - Thực hành: + Cấu hình chi tiết hệ thống tệp + Chọn VPC hiện có + Chọn AWS Managed Microsoft AD (Cung cấp tên miền DNS, tài khoản dịch vụ và mật khẩu) + Đặt tên chia sẻ tệp Windows (chọn AWS Managed Microsoft AD) + Kiểm tra và tạo hệ thống 29/10/2025 30/10/2025 https://000025.awsstudygroup.com/ 6 - Học về AWS X-Ray: + Trace + Segment + Subsegment + Annotation / Metadata + Service Map 30/10/2025 31/10/2025 https://000140.awsstudygroup.com/ Thành tựu Tuần 8 (Week 8 Achievements): Đã học và giải thích được 7 trạng thái của AWS Step Functions, bao gồm vai trò của từng trạng thái trong việc tự động hóa và điều phối quy trình.\nThực hành xây dựng workflow mẫu bằng AWS Step Functions trong Cloud9, triển khai cơ chế xử lý lỗi và xác minh luồng thực thi thành công.\nNắm vững kiến thức về các loại Amazon FSx và trường hợp sử dụng phù hợp cho từng nhu cầu: hệ thống Windows, tính toán hiệu năng cao, và lưu trữ doanh nghiệp.\nHoàn thành thực hành cấu hình FSx for Windows File Server, bao gồm: cấu hình hệ thống tệp, tích hợp VPC và Active Directory, và tạo chia sẻ file (file share).\nHiểu rõ cách AWS X-Ray thu thập và hiển thị trace, segment, subsegment, đồng thời quan sát Service Map để phát hiện nút thắt hiệu năng và lỗi trong ứng dụng.\nHoàn tất toàn bộ mục tiêu học tập và thực hành đề ra cho tuần 8.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "Các dịch vụ AWS vươn lên tầm cao mới trong Prime Day 2025: các số liệu và cột mốc chính Amazon Prime Day 2025 là sự kiện mua sắm Prime Day lớn nhất từ trước đến nay, thiết lập kỷ lục cả về khối lượng bán hàng và tổng số sản phẩm được bán ra trong suốt 4 ngày diễn ra sự kiện. Các thành viên Prime đã tiết kiệm hàng tỷ đô la khi mua sắm hàng triệu ưu đãi trên Amazon trong sự kiện này.\nNăm nay đánh dấu một sự chuyển đổi đáng kể trong trải nghiệm Prime Day nhờ những tiến bộ trong các dịch vụ AI tạo sinh của Amazon và AWS. Khách hàng đã sử dụng Alexa+ — trợ lý cá nhân thế hệ tiếp theo của Amazon hiện có sẵn trong giai đoạn truy cập sớm cho hàng triệu khách hàng — cùng với trợ lý mua sắm được hỗ trợ AI, Rufus, và Hướng dẫn mua sắm AI. Những tính năng này, được xây dựng dựa trên hơn 15 năm đổi mới đám mây và chuyên môn về học máy từ AWS, kết hợp với kinh nghiệm bán lẻ và người tiêu dùng sâu rộng từ Amazon, đã giúp khách hàng nhanh chóng khám phá các ưu đãi và có được thông tin sản phẩm, bổ sung cho dịch vụ giao hàng nhanh, miễn phí mà thành viên Prime tận hưởng quanh năm.\nNhư một phần trong truyền thống hằng năm của chúng tôi nhằm chia sẻ về cách AWS đã hỗ trợ Prime Day với doanh số kỷ lục, tôi muốn giới thiệu các dịch vụ và những số liệu ấn tượng từ AWS đã tạo nên trải nghiệm mua sắm tuyệt vời của bạn.\nPrime Day 2025 – tất cả các con số Trong những tuần trước các sự kiện mua sắm lớn như Prime Day, các trung tâm hoàn thiện đơn hàng và trạm giao hàng của Amazon hoạt động để chuẩn bị sẵn sàng và đảm bảo vận hành hiệu quả, an toàn. Ví dụ, hệ thống lưu trữ và truy xuất tự động (ASRS) của Amazon vận hành một đội ngũ robot di động công nghiệp toàn cầu để di chuyển hàng hóa trong các trung tâm hoàn thiện đơn hàng.\nAWS Outposts, một dịch vụ được quản lý toàn phần mở rộng trải nghiệm AWS đến môi trường tại chỗ, cung cấp sức mạnh cho các ứng dụng phần mềm quản lý điều khiển và vận hành ASRS, và hỗ trợ giao hàng trong ngày và ngày kế tiếp thông qua xử lý độ trễ thấp cho các lệnh điều khiển robot quan trọng.\nTrong Prime Day 2025, AWS Outposts tại một trong những trung tâm hoàn thiện đơn hàng lớn nhất đã gửi hơn 524 triệu lệnh đến hơn 7.000 robot, đạt đỉnh 8 triệu lệnh mỗi giờ — tăng 160% so với Prime Day 2024.\nDưới đây là một số số liệu thú vị và ấn tượng khác:\nAmazon Elastic Compute Cloud (Amazon EC2) – Trong Prime Day 2025, AWS Graviton, một bộ vi xử lý được thiết kế để mang lại hiệu suất/chi phí tốt nhất cho các khối lượng công việc trên Amazon EC2, đã cung cấp hơn 40% năng lực tính toán Amazon EC2 được Amazon.com sử dụng. Amazon cũng đã triển khai hơn 87.000 chip AWS Inferentia và AWS Trainium — chip silicon tùy chỉnh dành cho huấn luyện và suy luận AI/học sâu — để hỗ trợ Amazon Rufus trong Prime Day.\nAmazon SageMaker AI — Amazon SageMaker AI, một dịch vụ được quản lý toàn phần tập hợp nhiều công cụ cho học máy hiệu suất cao và chi phí thấp, đã xử lý hơn 626 tỷ yêu cầu suy luận trong Prime Day 2025.\nAmazon Elastic Container Service (Amazon ECS) và AWS Fargate – Amazon ECS, dịch vụ điều phối container được quản lý toàn phần, kết hợp với AWS Fargate, một công cụ tính toán serverless cho container, đã khởi chạy trung bình 18,4 triệu tác vụ mỗi ngày trên AWS Fargate trong Prime Day 2025, tăng 77% so với mức trung bình của Prime Day năm trước.\nAWS Fault Injection Service (AWS FIS) – Chúng tôi đã chạy hơn 6.800 thí nghiệm AWS FIS — nhiều gấp tám lần so với năm 2024 — để kiểm tra khả năng chịu lỗi và đảm bảo Amazon.com luôn khả dụng trong Prime Day. Sự gia tăng đáng kể này có được nhờ hai cải tiến: hỗ trợ mới cho các thí nghiệm lỗi mạng trên Amazon ECS với AWS Fargate, và việc tích hợp thử nghiệm FIS vào pipeline CI/CD.\nAWS Lambda – AWS Lambda đã xử lý hơn 1,7 nghìn tỷ lượt gọi mỗi ngày trong Prime Day 2025.\nAmazon API Gateway – Trong Prime Day 2025, Amazon API Gateway đã xử lý hơn 1 nghìn tỷ yêu cầu dịch vụ nội bộ — tăng trung bình 30% mỗi ngày so với Prime Day 2024.\nAmazon CloudFront – Amazon CloudFront đã phân phát hơn 3 nghìn tỷ yêu cầu HTTP trong tuần Prime Day toàn cầu 2025, tăng 43% so với Prime Day 2024.\nAmazon Elastic Block Store (Amazon EBS) – Trong Prime Day 2025, Amazon EBS đã đạt đỉnh 20,3 nghìn tỷ thao tác I/O, di chuyển đến 1 exabyte dữ liệu mỗi ngày.\nAmazon Aurora – Trong Prime Day, Amazon Aurora đã xử lý 500 tỷ giao dịch, lưu trữ 4.071 terabyte dữ liệu, và truyền 999 terabyte dữ liệu.\nAmazon DynamoDB – Amazon DynamoDB đã xử lý hàng chục nghìn tỷ cuộc gọi API trong Prime Day, duy trì tính khả dụng cao với thời gian phản hồi đơn vị mili-giây, và đạt đỉnh 151 triệu yêu cầu mỗi giây.\nAmazon ElastiCache – Trong Prime Day, Amazon ElastiCache đã đạt đỉnh hơn 1,5 triệu tỷ yêu cầu mỗi ngày và hơn 1,4 nghìn tỷ yêu cầu trong một phút.\nAmazon Kinesis Data Streams – Đã xử lý đỉnh 807 triệu bản ghi mỗi giây trong Prime Day 2025.\nAmazon Simple Queue Service (Amazon SQS) – Trong Prime Day 2025, Amazon SQS đã thiết lập kỷ lục lưu lượng mới với 166 triệu tin nhắn mỗi giây.\nAmazon GuardDuty – Trong Prime Day 2025, Amazon GuardDuty đã giám sát trung bình 8,9 nghìn tỷ sự kiện log mỗi giờ, tăng 48,9% so với Prime Day năm ngoái.\nAWS CloudTrail – AWS CloudTrail đã xử lý hơn 2,5 nghìn tỷ sự kiện trong Prime Day 2025, so với 976 tỷ sự kiện trong năm 2024.\nSẵn sàng để mở rộng quy mô\nNếu bạn đang chuẩn bị cho các sự kiện quan trọng đối với doanh nghiệp như ra mắt sản phẩm, di chuyển hệ thống, và các cuộc di cư khác, tôi khuyên bạn nên tận dụng AWS Countdown (trước đây gọi là AWS Infrastructure Event Management, hay IEM). Đây là một chương trình hỗ trợ toàn diện giúp đánh giá mức độ sẵn sàng vận hành, xác định và giảm thiểu rủi ro, và lập kế hoạch năng lực, sử dụng các playbook đã được chứng minh do các chuyên gia AWS phát triển.Chúng tôi đã mở rộng để bao gồm: generative AI implementation support nhằm giúp bạn tự tin ra mắt và mở rộng các sáng kiến AI; migration and modernization support, bao gồm mainframe modernization; và tối ưu hóa hạ tầng cho các lĩnh vực chuyên biệt bao gồm election systems, retail operations, healthcare services, và sports and gaming events.\nTôi mong được chứng kiến những kỷ lục nào khác sẽ bị phá vỡ vào năm tới!\n— Channy\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "\rAWS được công nhận là Nhà lãnh đạo trong báo cáo Gartner Magic Quadrant 2025 về Nền tảng Ứng dụng Cloud-Native và Quản lý Container Một tháng trước, mình đã chia sẻ rằng Amazon Web Services (AWS) được công nhận làLeader in 2025 Gartner Magic Quadrant for Strategic Cloud Platform Services (SCPS),đánh dấu năm thứ mười lăm liên tiếp AWS được Gartner xếp hạng là Nhà lãnh đạo.\nNăm 2024, AWS được công nhận là Nhà lãnh đạo trong nhiều báo cáo Gartner Magic Quadrant, bao gồm: AI Code Assistants, Cloud-Native Application Platforms, Cloud Database Management Systems, Container Management, Data Integration Tools, Desktop as a Service (DaaS), and Data Science and Machine Learning Platforms as cũng như SCPS.Sang năm 2025, AWS tiếp tục được công nhận là Nhà lãnh đạo trong Gartner Magic Quadrant cho Contact Center as a Service (CCaaS), Desktop as a Service và Data Science and Machine Learning (DSML) nền tảng. Chúng tôi tin tưởng rằng điều này cho thấy AWS đang cung cấp danh mục dịch vụ rộng và sâu nhất cho khách hàng.\nHôm nay, mình vui mừng chia sẻ các báo cáo Magic Quadrant mới nhất, trong đó AWS được vinh danh là Nhà lãnh đạo trong nhiều thị trường công nghệ đám mây: Nền tảng Ứng dụng Cloud-Native (còn gọi là Nền tảng Ứng dụng Đám mây) và Quản lý Container.\n2025 Gartner Magic Quadrant for Cloud-Native Application Platforms AWS đã được công nhận là Nhà lãnh đạo trong Gartner Magic Quadrant cho Nền tảng Ứng dụng Cloud-Native trong 2 năm liên tiếp. AWS được xếp hạng cao nhất về “Khả năng Thực thi”.\nGartner định nghĩa nền tảng ứng dụng cloud-native là những dịch vụ cung cấp môi trường runtime được quản lý cho ứng dụng, cùng các khả năng tích hợp để quản lý vòng đời của ứng dụng hoặc thành phần ứng dụng trong môi trường đám mây.\nDanh mục ứng dụng cloud-native toàn diện của chúng tôi—AWS Lambda, AWS App Runner, AWS Amplify, and AWS Elastic Beanstalk—mang đến sự linh hoạt để xây dựng các ứng dụng hiện đại với khả năng AI mạnh mẽ, nhờ đổi mới liên tục và tích hợp sâu rộng trong toàn bộ danh mục dịch vụ AWS.\nKhách hàng có thể dễ dàng lựa chọn dịch vụ thông qua tài liệu chi tiết, kiến trúc tham chiếu, và hướng dẫn có sẵn trong AWS Solutions Library, cùng với khuyến nghị ngữ cảnh được hỗ trợ bởi AI từ Amazon Q dựa trên yêu cầu cụ thể. Mặc dù AWS Lambda được tối ưu hóa cho AWS để mang lại trải nghiệm serverless (không máy chủ) tốt nhất, nhưng nó vẫn tuân theo các tiêu chuẩn của ngành về điện toán serverless và hỗ trợ các ngôn ngữ lập trình cũng như framework phổ biến. Bạn có thể tìm thấy tất cả các khả năng cần thiết trong AWS, bao gồm các tính năng nâng cao cho AI/ML, điện toán biên (edge computing) và tích hợp doanh nghiệp.\nBạn có thể xây dựng, triển khai, và mở rộng các ứng dụng generative AI bằng cách tích hợp các dịch vụ compute này với Amazon Bedrock để thực hiện suy luận serverless, vàAmazon SageMaker cho cho việc huấn luyện và quản lý artificial intelligence and machine learning (AI/ML).\nTruy cập 2025 Gartner Magic Quadrant for Cloud-Native Application Platforms để xem thêm thông tin.\nGartner Magic Quadrant 2025 cho Quản lý Container Trong báo cáo Gartner Magic Quadrant 2025 cho Quản lý Container, AWS tiếp tục được công nhận là Nhà lãnh đạo trong 3 năm liên tiếp và được xếp hạng xa nhất về “Độ hoàn thiện Tầm nhìn”.\nGartner định nghĩa quản lý container là các dịch vụ hỗ trợ triển khai và vận hành workloads được container hóa. Quá trình này bao gồm việc điều phối và giám sát toàn bộ vòng đời container—từ triển khai, mở rộng, đến vận hành—để đảm bảo hiệu năng và tính nhất quán trên nhiều môi trường khác nhau.\nAWS container services cung cấp quản lý container được AWS vận hành toàn phần, kết hợp giữa công nghệ gốc của AWS và mã nguồn mở, mang lại nhiều lựa chọn triển khai từ Kubernetes cho đến bộ điều phối native.\nBạn có thể sử dụng Amazon Elastic Container Service (Amazon ECS) và Amazon Elastic Kubernetes Service (Amazon EKS). cả hai đều có thể chạy với AWS Fargate để triển khai container serverless. Ngoài ra, EKS Auto Mode đơn giản hóa việc quản lý Kubernetes bằng cách tự động cung cấp hạ tầng, chọn instance tối ưu, và mở rộng tài nguyên động cho ứng dụng container.\nĐể kết nối hạ tầng on-premises hoặc edge với dịch vụ container của AWS, bạn có thể dùng EKS Hybrid Nodes and ECS Anywhere, hoặc dùng EKS Anywhere cho trải nghiệm Kubernetes tách biệt hoàn toàn nhưng vẫn được AWS hỗ trợ. Với các tùy chọn compute và triển khai linh hoạt, bạn có thể giảm chi phí vận hành, tập trung đổi mới, và mang lại giá trị kinh doanh nhanh hơn.\nTruy cập vào 2025 Gartner Magic Quadrant for Container Management để xem thêm thông tin.\n— Channy\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.4-blog4/",
	"title": "Blog 4",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.5-blog5/",
	"title": "Blog 5",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.6-blog6/",
	"title": "Blog 6",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/",
	"title": "Chuẩn bị tài nguyên",
	"tags": [],
	"description": "",
	"content": "Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBài thu hoạch “GenAI-powered App-DB Modernization workshop” Mục Đích Của Sự Kiện Chia sẻ best practices trong thiết kế ứng dụng hiện đại Giới thiệu phương pháp DDD và event-driven architecture Hướng dẫn lựa chọn compute services phù hợp Giới thiệu công cụ AI hỗ trợ development lifecycle Danh Sách Diễn Giả Jignesh Shah - Director, Open Source Databases Erica Liu - Sr. GTM Specialist, AppMod Fabrianne Effendi - Assc. Specialist SA, Serverless Amazon Web Services Nội Dung Nổi Bật Đưa ra các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu/bỏ lỡ cơ hội Hoạt động kém hiệu quả → Mất năng suất, tốn kém chi phí Không tuân thủ các quy định về bảo mật → Mất an ninh, uy tín Chuyển đổi sang kiến trúc ứng dụng mới - Microservice Architecture Chuyển đổi thành hệ thống modular – từng chức năng là một dịch vụ độc lập giao tiếp với nhau qua sự kiện với 3 trụ cột cốt lõi:\nQueue Management: Xử lý tác vụ bất đồng bộ Caching Strategy: Tối ưu performance Message Handling: Giao tiếp linh hoạt giữa services Domain-Driven Design (DDD) Phương pháp 4 bước: Xác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts Case study bookstore: Minh họa cách áp dụng DDD thực tế Context mapping: 7 patterns tích hợp bounded contexts Event-Driven Architecture 3 patterns tích hợp: Publish/Subscribe, Point-to-point, Streaming Lợi ích: Loose coupling, scalability, resilience So sánh sync vs async: Hiểu rõ trade-offs (sự đánh đổi) Compute Evolution Shared Responsibility Model: Từ EC2 → ECS → Fargate → Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria lựa chọn phù hợp Amazon Q Developer SDLC automation: Từ planning đến maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Những Gì Học Được Tư Duy Thiết Kế Business-first approach: Luôn bắt đầu từ business domain, không phải technology Ubiquitous language: Importance của common vocabulary giữa business và tech teams Bounded contexts: Cách identify và manage complexity trong large systems Kiến Trúc Kỹ Thuật Event storming technique: Phương pháp thực tế để mô hình hóa quy trình kinh doanh Sử dụng Event-driven communication thay vì synchronous calls Integration patterns: Hiểu khi nào dùng sync, async, pub/sub, streaming Compute spectrum: Criteria chọn từ VM → containers → serverless Chiến Lược Hiện Đại Hóa Phased approach: Không rush, phải có roadmap rõ ràng 7Rs framework: Nhiều con đường khác nhau tùy thuộc vào đặc điểm của mỗi ứng dụng ROI measurement: Cost reduction + business agility Ứng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại: Event storming sessions với business team Refactor microservices: Sử dụng bounded contexts để identify service boundaries Implement event-driven patterns: Thay thế một số sync calls bằng async messaging Serverless adoption: Pilot AWS Lambda cho một số use cases phù hợp Try Amazon Q Developer: Integrate vào development workflow để boost productivity Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đến từ AWS và các tổ chức công nghệ lớn đã chia sẻ best practices trong thiết kế ứng dụng hiện đại. Qua các case study thực tế, tôi hiểu rõ hơn cách áp dụng Domain-Driven Design (DDD) và Event-Driven Architecture vào các project lớn. Trải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về event storming giúp tôi hình dung cách mô hình hóa quy trình kinh doanh thành các domain events. Học cách phân tách microservices và xác định bounded contexts để quản lý sự phức tạp của hệ thống lớn. Hiểu rõ trade-offs giữa synchronous và asynchronous communication cũng như các pattern tích hợp như pub/sub, point-to-point, streaming. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Q Developer, công cụ AI hỗ trợ SDLC từ lập kế hoạch đến maintenance. Học cách tự động hóa code transformation và pilot serverless với AWS Lambda, từ đó nâng cao năng suất phát triển. Kết nối và trao đổi Workshop tạo cơ hội trao đổi trực tiếp với các chuyên gia, đồng nghiệp và team business, giúp nâng cao ngôn ngữ chung (ubiquitous language) giữa business và tech. Qua các ví dụ thực tế, tôi nhận ra tầm quan trọng của business-first approach, luôn bắt đầu từ nhu cầu kinh doanh thay vì chỉ tập trung vào công nghệ. Bài học rút ra Việc áp dụng DDD và event-driven patterns giúp giảm coupling, tăng scalability và resilience cho hệ thống. Chiến lược hiện đại hóa cần phased approach và đo lường ROI, không nên vội vàng chuyển đổi toàn bộ hệ thống. Các công cụ AI như Amazon Q Developer có thể boost productivity nếu được tích hợp vào workflow phát triển hiện tại. Một số hình ảnh khi tham gia sự kiện Thêm các hình ảnh của các bạn tại đây Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "\rTuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc với Amazon RDS,AWS DynamoDB, LightSail và EC2 Auto Scaling\nTuần 3: Học về AWS Security\nTuần 4: Học về AWS DynamoDB và Relational Database Services\nTuần 5: Phân quyền và lưu trữ\nTuần 6: Mã hóa dữ liệu\nTuần 7: Tối ưu hiệu năng\nTuần 8: setup networking, Phân quyền, và chia sẻ file\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event1/",
	"title": "Sự kiện 1",
	"tags": [],
	"description": "",
	"content": "Báo cáo tổng kết: “Data Science on AWS” Mục tiêu sự kiện Khám phá cách AWS giải quyết các bài toán dữ liệu bằng dịch vụ của mình Giới thiệu tổng quan về các Managed AI Services và các trường hợp sử dụng thực tế Chuẩn bị dữ liệu với Amazon SageMaker Ứng dụng XGBoost trong SageMaker Studio Notebooks Khai thác AutoML không cần code với SageMaker Canvas Diễn giả Văn Hoàng Kha – Cloud Solutions Architect, AWS User Group Leader Bạch Doãn Vương – Cloud DevOps Engineer, AWS Community Builder Đoàn Nguyễn Thanh Hòa – Giảng viên CF, Đại học FPT TP.HCM Nội dung nổi bật (Key Highlights) Amazon Comprehend và Amazon Translate Phân tích và dịch văn bản bằng công nghệ học sâu (Deep Learning)\nXử lý nhiều loại tài liệu như email, chat, mạng xã hội, cuộc gọi\u0026hellip; và tự động trích xuất thông tin hữu ích. Các trường hợp sử dụng phổ biến của Amazon Comprehend: Xử lý tài liệu thông minh Tự động hóa quy trình email Phân loại và định tuyến ticket hỗ trợ khách hàng Gắn thẻ tài liệu và nội dung media Phân tích cảm xúc khách hàng Phân tích cuộc gọi tổng đài Phát hiện và ẩn thông tin nhạy cảm (PII) Amazon Translate Dịch máy thần kinh (Neural Machine Translation)\nTính năng chính:\nHỗ trợ ngôn ngữ rộng: 4970 cặp ngôn ngữ dịch X↔Y Độ trễ thấp: \u0026lt;150ms cho mỗi câu Bảo mật dữ liệu: mã hóa và quản lý truy cập đầy đủ Phủ sóng khu vực rộng: 17 vùng AWS Tùy chỉnh dịch: dùng Custom Terminologies và Active Custom Translation Dịch hàng loạt: hỗ trợ định dạng DOCX, PPTX, XLSX, XML, HTML, TXT Mô hình huấn luyện đa lĩnh vực: 11 domain khác nhau Tính phí theo sử dụng: dễ tích hợp qua API Trường hợp sử dụng:\nBản địa hóa nội dung: tài liệu doanh nghiệp, phụ đề video, lưu trữ Giao tiếp: tương tác khách hàng, chat trong game, bài viết mạng xã hội Phân tích văn bản: Voice of Customer, phân tích media, eDiscovery Amazon Polly Dịch vụ chuyển văn bản thành giọng nói (Text-to-Speech)\nAmazon Polly sử dụng công nghệ học sâu để tổng hợp giọng nói tự nhiên như con người.\nTính năng:\nText-to-Speech (TTS) Ngôn ngữ đánh dấu SSML Tùy chỉnh từ vựng (Lexicons) Dấu giọng nói (Speech Marks) Tạo giọng thương hiệu (Brand Voice) Ứng dụng thực tế:\nĐọc tin tức, tài liệu đào tạo Tổng đài thoại/IVR Podcast, học ngoại ngữ Dẫn đường, nhắc việc, công cụ hỗ trợ người khuyết tật Amazon Transcribe Dịch vụ nhận dạng giọng nói tự động (ASR)\nChuyển nội dung âm thanh/video thành văn bản Hỗ trợ cả ghi âm sẵn và phát trực tiếp theo thời gian thực Amazon Lex Dịch vụ xây dựng chatbot và giao diện hội thoại thông minh\nTính năng:\nDễ sử dụng Hiểu ngôn ngữ tự nhiên chính xác Tích hợp sẵn với hệ sinh thái AWS Tiết kiệm chi phí Amazon Rekognition Phân tích hình ảnh và video để phát hiện đối tượng, khuôn mặt, cảnh vật và nội dung không phù hợp.\nAmazon Personalize Cá nhân hóa trải nghiệm người dùng\nTriển khai hệ thống gợi ý nhanh chóng Phản ứng theo hành vi người dùng theo thời gian thực Dễ dàng tích hợp với hệ thống hiện có Giảm thời gian ra thị trường nhờ dịch vụ ML được quản lý Feature Engineering Chuẩn bị dữ liệu với Amazon SageMaker Canvas Ứng dụng vào công việc — Bài học rút ra từ Key Highlights 1. Hiểu dữ liệu \u0026amp; Tự động hóa (Amazon Comprehend, Translate) Bài học:\nKhai thác dữ liệu phi cấu trúc là nền tảng cho việc ra quyết định thông minh.\nỨng dụng:\nSử dụng Amazon Comprehend để phân tích cảm xúc khách hàng, phân loại tài liệu hoặc email. Tự động định tuyến ticket hỗ trợ dựa trên nội dung và cảm xúc. Dùng Amazon Translate để dịch nhanh tài liệu trong các dự án đa ngôn ngữ. 2. Tăng tương tác \u0026amp; Giao diện thoại (Amazon Polly, Lex, Transcribe) Bài học:\nAI giọng nói giúp nâng cao trải nghiệm người dùng và khả năng tiếp cận dịch vụ.\nỨng dụng:\nKết hợp Lex + Transcribe + Polly để xây dựng chatbot hỗ trợ khách hàng bằng giọng nói 24/7. Sử dụng Polly tạo giọng đọc tự nhiên cho nội dung đào tạo hoặc podcast. Dùng Transcribe để ghi âm, phân tích và tóm tắt nội dung cuộc họp hoặc cuộc gọi. 3. Phân tích hình ảnh \u0026amp; video (Amazon Rekognition) Bài học:\nThị giác máy tính giúp tự động hóa việc phân tích và kiểm duyệt nội dung đa phương tiện.\nỨng dụng:\nÁp dụng Rekognition để tự động gắn thẻ, phân loại hình ảnh/video. Phát hiện khuôn mặt hoặc hành vi bất thường trong hệ thống an ninh hoặc bán lẻ. 4. Cá nhân hóa trải nghiệm người dùng (Amazon Personalize) Bài học:\nCá nhân hóa là yếu tố cốt lõi để giữ chân người dùng và nâng cao trải nghiệm.\nỨng dụng:\nTích hợp Personalize để gợi ý sản phẩm/dịch vụ theo hành vi người dùng. Xây dựng hệ thống gợi ý phản hồi theo thời gian thực, thích ứng liên tục. 5. Đơn giản hóa Machine Learning (Amazon SageMaker, Canvas) Bài học:\nMachine Learning không còn là đặc quyền của chuyên gia — AWS giúp AI trở nên dễ tiếp cận.\nỨng dụng:\nDùng SageMaker Canvas để huấn luyện và dự đoán mà không cần viết code. Ứng dụng SageMaker Studio để thử nghiệm các mô hình như XGBoost. Hiểu rõ vai trò của Feature Engineering để cải thiện độ chính xác của mô hình. 6. Tư duy hiện đại hóa dựa trên dữ liệu Bài học:\nCác dịch vụ AI của AWS thúc đẩy tư duy kiến trúc hướng sự kiện (event-driven) và tập trung vào dữ liệu.\nỨng dụng:\nKết hợp Domain-Driven Design (DDD) với quy trình AI để xây dựng hệ thống linh hoạt, dễ mở rộng. Sử dụng serverless (Lambda, API Gateway) để triển khai nhanh các pipeline AI. Thiết kế hệ thống xử lý dữ liệu bất đồng bộ theo mô hình event streaming để tăng hiệu năng. 🌟 Tổng kết Qua hội thảo “Data Science on AWS”, tôi không chỉ học về từng dịch vụ AI riêng lẻ mà còn hiểu được cách liên kết chúng thành một hệ sinh thái dữ liệu thông minh.\nMỗi công cụ — từ Comprehend, Translate, Polly, Rekognition, Personalize đến SageMaker — đều góp phần tạo nên hệ thống tự động, linh hoạt và hướng người dùng.\nNhững kiến thức và bài học này có thể áp dụng trực tiếp vào dự án thực tế, giúp chuyển đổi quy trình thủ công sang mô hình vận hành thông minh dựa trên AI và dữ liệu.\nHình ảnh sự kiện (Thêm ảnh sự kiện của bạn tại đây)\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/",
	"title": "Tạo một Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": " Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Tuần 9: Hiểu và áp dụng AWS AppSync để xây dựng GraphQL API với nhiều nguồn dữ liệu khác nhau. Học và cấu hình AWS EBS Data Lifecycle Manager để tự động hóa việc sao lưu và khôi phục dữ liệu. Tìm hiểu AWS GuardDuty để phát hiện mối đe dọa thông minh bằng Machine Learning và phân tích hành vi. Nghiên cứu AWS Macie nhằm phát hiện và bảo vệ dữ liệu nhạy cảm trong S3 bucket bằng trí tuệ nhân tạo. Nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học AWS AppSync: + GraphQL APIs: Query, Mutation, Subscription + Nguồn dữ liệu: DynamoDB, RDS/Aurora, AWS Lambda, HTTP Endpoints, OpenSearch + Xác thực và phân quyền: AWS IAM, API Keys, Cognito User Pools, OpenID Connect + Hỗ trợ Realtime, Caching, Offline - Thực hành: + Tạo GraphQL API + Thiết kế schema và gắn với data source + Cấu hình request/response mapping templates 02/11/2025 03/11/2025 https://000086.awsstudygroup.com/1-introduction/ 3 - Học AWS EBS Data Lifecycle Manager: + Tự động hóa sao lưu và khôi phục dữ liệu + Giảm chi phí lưu trữ + Đảm bảo tuân thủ và bảo mật dữ liệu + Hiểu về các loại Lifecycle Policies: EBS Snapshot Policy, EBS-backed AMI Policy, Cross-region/ Cross-account Copy Policy 03/11/2025 05/11/2025 https://000088.awsstudygroup.com/ 4 - Thực hành: + Khởi tạo EC2 và cấu hình lifecycle policies + Xác định tài nguyên cần sao lưu, tần suất và thời gian lưu trữ - Học AWS GuardDuty: + Hiểu cơ chế phát hiện mối đe dọa bằng ML và phân tích hành vi 03/11/2025 06/11/2025 https://000098.awsstudygroup.com/ 5 - Học AWS Macie: + Các tính năng chính: Data Discovery, Classification, Bucket-level Visibility + Cách hoạt động của Macie + Trường hợp sử dụng và mô hình tính phí 08/14/2025 08/15/2025 https://000090.awsstudygroup.com/ 6 - Thực hành với AWS Macie: + Tạo và cấu hình S3 bucket + Kích hoạt dịch vụ Macie + Tạo Macie job để quét và phân loại dữ liệu 08/15/2025 08/15/2025 https://000090.awsstudygroup.com/ Kết quả đạt được trong tuần: Trong tuần này, tôi đã học và thực hành nhiều dịch vụ AWS liên quan đến bảo mật và quản lý dữ liệu:\nAWS AppSync: Xây dựng thành công GraphQL API tích hợp với DynamoDB và Lambda, nắm được cách thiết kế schema, resolver và mapping template. AWS EBS Lifecycle Manager: Cấu hình chính sách sao lưu tự động giúp tăng tính tin cậy và giảm chi phí vận hành. AWS GuardDuty: Hiểu cơ chế phát hiện mối đe dọa tự động dựa trên Machine Learning và phân tích hành vi bất thường. AWS Macie: Kích hoạt Macie cho S3, chạy job phân loại dữ liệu và phân tích kết quả phát hiện dữ liệu nhạy cảm để đảm bảo tuân thủ bảo mật. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập - Thực hành: +Tạo AWS Free Tier account 08/09/2025 09/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ: + AWS EC2 + AWS Lambda + AWS SQS + AWS SNS + CLI,SDKs 09/09/2025 10/09/2025 4 - Tìm hiểu AWS ECS, AWS EKS, VPC, và AWS CloudFormation - Quản lý chi phí - Thực hành: + Tạo EC2 instance và Lambda function +Sử dụng AWS CLI 10/09/2025 11/09/2025 5 - Tìm hiểu VPC cơ bản và S3 - Thực hành: +Tạo Security group +Tạo Internet Gateway +Tạo Subnet +Tạo Route tables 11/09/2025 12/09/2025 6 - Thực hành: + Tạo S3 bucket 12/09/2025 13/09/2025 Kết quả đạt được tuần 1: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nSử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": "\rMục tiêu tuần 2: Học về Amazon RDS,AWS S3, AWS EC2 Auto Scaling, AWS DynamoDB và Amazon LightSail. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS DynamoDB,AWS RDS,Amazon Aurora -Practice:\n+Tạo AWS CloudFront và AWS S3 tập 14/09/2025 15/09/2025 https://render.skillbuilder.aws/?module_id=B1DGAV8S16%3A001.000.000\u0026product_id=8D79F3AVR7%3A002.000.000\u0026registration_id=c9de1df5-b12f-5abf-84c4-aac56a36dcae\u0026navigation=digital\u0026parentId=Y4YASRJEVX 3 -Thực hành:\n+Tạo AWS RDS +Tạo DynamoDB bằng cách sử dụng Python và AWS CLI 15/09/2025 16/09/2025 https://render.skillbuilder.aws/?module_id=B1DGAV8S16%3A001.000.000\u0026product_id=8D79F3AVR7%3A002.000.000\u0026registration_id=c9de1df5-b12f-5abf-84c4-aac56a36dcae\u0026navigation=digital\u0026parentId=Y4YASRJEVX 4 - Dịch blog 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 Auto Scaling cơ bản, điện toán đơn giản hóa cùng Amazon LightSail - Thực hành: +Tạo Database trong AWS RDS +Sử dụng Amazon LightSail 19/09/2025 20/09/2025 https://000005.awsstudygroup.com/ https://000045.awsstudygroup.com/ 6 - Thực hành: + Tạo RDS, VPC, EC2 cùng dịch vụ AWS EC2 Auto Scaling 20/09/2025 21/09/2025 https://000006.awsstudygroup.com/ Kết quả đạt được tuần 2: Lưu trữ và triển khai websites tĩnh với Amazon S3:\nBiết cách tạo bucket S3, tải file lên và quản lý quyền truy cập. Biết cách bật tính năng Static Website Hosting cho bucket. Học cách cấu hình quyền public để website có thể truy cập qua Internet. Học cách cấu hình Bucket policy để chỉ cho phép truy cập đọc công khai. Cơ sở dữ liệu thiết yếu cùng với Amazon Relational Databases Services:\nHỗ trợ nhiều engine phổ biến như MySQL,PostgreSQL,Oracle, và SQL Server. Học cách kết nối đến RDS từ EC2. Hiểu về endpoint, port,username/password để truy cập DB. Học cách sử dụng VPC, subnet, security group để bảo vệ RDS instance. Ứng dụng mở rộng quy mô với EC2 Auto Scaling:\nLà dịch vụ giúp tự động tăng hoặc giảm số lượng Amazon EC2 instance dựa trên nhu cầu ứng dụng. Thành phần của Auto Scaling: Launch Configuration/ Launch Template Auto Scaling Group(ASG) Chính sách mở rộng: Dynamic Scaling và Schedule Scaling Health checks Dựa vào Amazon CloudWatch để thu thập metrics như: CPU utilization, network traffic, request const. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": "\rMục tiêu tuần 3: Hiểu lý thuyết nền tảng về security Hiểu dịch vụ AWS KMS, AWS Macie và AWS Certificate Manager. Hiểu được cách bảo vệ cơ sở hạ tầng Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 Học cách bảo vệ dữ liệu bằng cách sử dụng bảo vệ của AWS(Amazon S3, Amazon EBS, Amazon DynamoDB) và dịch vụ bảo vệ dữ liệu của AWS(AWS KMS, Amazon Macie, AWS Certificate Manager) 22/09/2025 23/09/2025 https://render.skillbuilder.aws/?module_id=TNAPD78T9R%3A001.000.000\u0026product_id=8D79F3AVR7%3A002.000.000\u0026registration_id=c9de1df5-b12f-5abf-84c4-aac56a36dcae\u0026navigation=digital\u0026parentId=Y4YASRJEVX 3 Học cách bảo vệ mạng và ứng dụng bằng cách sử dụng bảo vệ dữ liệu thông cơ sở hạ tầng của AWS(Security groups, ELB, AWS regions) và dịch vụ AWS bảo vệ dữ liệu(AWS shield, AWS WAF) 23/09/2025 24/09/2025 https://render.skillbuilder.aws/?module_id=TNAPD78T9R%3A001.000.000\u0026product_id=8D79F3AVR7%3A002.000.000\u0026registration_id=c9de1df5-b12f-5abf-84c4-aac56a36dcae\u0026navigation=digital\u0026parentId=Y4YASRJEVX 4 -Tìm hiểu cách phát hiện và ứng phó với các sự cố bảo mật bằng cách sử dụng Amazon Inspector, Amazon GuardDuty, Amazon Detective, Amazon Security Hub 24/09/2025 25/09/2025 https://render.skillbuilder.aws/?module_id=TNAPD78T9R%3A001.000.000\u0026product_id=8D79F3AVR7%3A002.000.000\u0026registration_id=c9de1df5-b12f-5abf-84c4-aac56a36dcae\u0026navigation=digital\u0026parentId=Y4YASRJEVX 5 - Tìm hiểu cách ngăn chặn truy cập trái phép bằng cách sử dụng các dịch vụ quản lý truy cập bổ sung như AWS IAM Identity Center, AWS Secrets Manager, AWS Systems Manager 25/09/2025 26/09/2025 https://render.skillbuilder.aws/?module_id=TNAPD78T9R%3A001.000.000\u0026product_id=8D79F3AVR7%3A002.000.000\u0026registration_id=c9de1df5-b12f-5abf-84c4-aac56a36dcae\u0026navigation=digital\u0026parentId=Y4YASRJEVX 6 - Thực hành: + Liên kết danh tính với AWS Single Sign-On 15/08/2025 15/08/2025 https://000012.awsstudygroup.com/ Kết quả đạt được tuần 3: Nắm kiến thức cơ bản về bảo mật dữ liệu AWS, bao gồm:\nCác phương thức mã hóa và quản lý khóa bằng AWS KMS Bảo mật dữ liệu nhạy cảm với Amazon Macie Quản lý chứng chỉ với AWS Certificate Manager Cơ chế bảo mật dữ liệu của S3,EBS,DynamoDB Hiểu các khái niệm về bảo vệ hạ tầng và ứng dụng:\nSecurity groups, Elastic Load Balancer(ELB), AWS Regions Cách thức hoạt động của AWS Shield và AWS WAF Học được vai trò của các dịch vụ trong phát hiện và phản ứng sự cố bảo mật:\nAmazon Inspector, GuardDuty, Amazon Detective, AWS Security Hub Hiểu cơ bản về ngăn chặn truy cập trái phép với:\nIAM Identity Center (SSO) AWS Secrets Manager AWS Systems Manager "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Thực hành tạo, quản lý, và triển khai các tài nguyên AWS thông qua các công cụ khác nhau (Console, CLI, SDK, Elastic Beanstalk\u0026hellip;). Xây dựng ứng dụng mẫu sử dụng Lambda, S3, DynamoDB, và API Gateway. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Pratice: Tạo table trong AWS DynamoDB bằng cách sử dụng AWS CLI hoặc Python thông qua AccessKey 28/09/2025 29/09/2025 3 - **Thực hành:**Tạo book store bằng cách sử dụng Lambda, S3 và DynamoDB 30/09/2025 01/10/2025 https://000078.awsstudygroup.com/ 4 - Tìm hiểu về Json \u0026amp; Document Model 01/10/2025 02/10/2025 5 - Thực hành: + Sử dụng AWS Console để deploy và xác minh AWS resources bằng AWS CloudFormation template. + Sử dụng AWS Tools cho Eclipse IDE để triển khai 1 ứng dụng Java trong môi trường Elastic Beanstalk. + Cài đặt và định cấu hình công cụ AWS Elastic Beanstalk CLI. + Sử dụng AWS Elastic Beanstalk CLI để triển khai 1 bản cập nhật trong môi trường Elastic Beanstalk environment có sẵn. + Sử dụng AWS SDK truy vấn và sửa đổi môi trường AWS environment bằng code. 03/10/2025 04/10/2025 https://000050.awsstudygroup.com/ 6 - Thực hành: + dựng một ứng dụng web (front-end) để tương tác với cơ sở dữ liệu thông qua Lambda và API Gateway. 04/10/2025 05/10/2025 https://000079.awsstudygroup.com/ Kết quả đạt được tuần 4: Hiểu và thao tác được với AWS DynamoDB:\nTạo và quản lý bảng DynamoDB thông qua AWS CLI và Python SDK (boto3) bằng Access Key. Biết cách xác định Primary Key, Sort Key, và cấu hình Read/Write Capacity Mode. Xây dựng ứng dụng Book Store sử dụng AWS Lambda, S3, và DynamoDB:\nTạo Lambda function để xử lý CRUD operations cho dữ liệu sách. Kết nối API Gateway với Lambda để tạo REST API phục vụ giao tiếp với frontend. Lưu trữ ảnh bìa sách và dữ liệu tĩnh trên S3 Bucket. Nắm vững mô hình dữ liệu JSON \u0026amp; Document Model:\nHiểu cách lưu trữ dữ liệu phi cấu trúc trong DynamoDB và cách truy xuất thông qua JSON format. Triển khai ứng dụng Java bằng Elastic Beanstalk:\nSử dụng AWS Console và CloudFormation Template để tự động hoá việc tạo môi trường. Cấu hình và sử dụng Elastic Beanstalk CLI để deploy và cập nhật ứng dụng. Tích hợp AWS SDK for Java để tương tác với môi trường ứng dụng Xây dựng ứng dụng web (frontend) kết nối Lambda + API Gateway + DynamoDB:\nTạo giao diện web đơn giản cho phép người dùng thêm, sửa, xóa dữ liệu trong DynamoDB. Hiểu quy trình Frontend → API Gateway → Lambda → DynamoDB và cách bảo mật endpoint. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS Amplify 05/10/2025 06/10/2025 https://aws.amazon.com/vi/amplify/ 3 - Thực hành: Serverless - Sử dụng authentication và storage 06/10/2025 09/10/2025 https://000134.awsstudygroup.com/ 4 - Tìm hiểu về AWS SAM : +AWS SAM templates và AWS SAM CLI +AWS SAM Accelerate và AWS SAM CLI Integration 09/10/2025 10/10/2025 https://aws.amazon.com/vi/serverless/sam/ 5 - Thực hành: + Tải SAM CLI + Deploy front-end và Lambda function + Cấu hình API Gateway và kiểm thử API by Postman 10/10/2025 11/10/2025 https://cloudjourney.awsstudygroup.com/ 6 -Tìm hiểu: Amazon Cognito -Thực hành: Bảo mật cùng với Amazon Cognito 11/10/2025 13/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: Tìm hiểu và thực hành với AWS Amplify, bao gồm:\nHiểu kiến trúc của Amplify và cách tích hợp với ứng dụng serverless. Triển khai xác thực người dùng (Amplify Authentication) cho tính năng đăng nhập và đăng ký. Sử dụng Amplify Storage để quản lý tải lên và truy cập tệp tin thông qua S3. Quản lý dự án Amplify bằng CLI và kết nối với ứng dụng front-end. Nghiên cứu và áp dụng AWS SAM (Serverless Application Model):\nHiểu về SAM templates, Lambda functions và tích hợp với API Gateway. Cài đặt và cấu hình SAM CLI. Thực hành triển khai ứng dụng serverless bằng SAM Accelerate. Triển khai hàm Lambda và kiểm thử API bằng Postman. Hiểu quy trình hoạt động giữa SAM, CloudFormation và hạ tầng serverless. Tìm hiểu và thực hành với Amazon Cognito:\nNắm được khái niệm User Pools và Identity Pools trong Cognito. Thực hiện xác thực và phân quyền người dùng thông qua Cognito. Tích hợp Cognito Authentication vào ứng dụng front-end bằng AWS Amplify. Thành công trong việc kiểm thử các quy trình đăng ký, đăng nhập và xác thực token. Xây dựng được khả năng kết hợp Amplify, SAM và Cognito để tạo nên một ứng dụng serverless hoàn chỉnh, có khả năng xác thực, tương tác API và triển khai trực tiếp trên AWS.\nCủng cố kiến thức về kiến trúc serverless, sẵn sàng cho các bài thực hành nâng cao về phát triển ứng dụng cloud-native.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Hiểu và thực hành AWS Backup, bao gồm Backup Vault, Backup Plan, và triển khai bằng AWS CloudFormation. Nắm bắt cách hoạt động của AWS WAF (Web Application Firewall) và AWS PrivateLink, hiểu các thành phần như ACL, Rule, Rule Group, VPC Endpoint Service và Network Load Balancer. Tìm hiểu AWS KMS (Key Management Service) — bao gồm symmetric/asymmetric keys và vai trò của mã hóa trong bảo mật hệ thống. Nắm vững khái niệm Containerization với Docker, hiểu quy trình tạo và triển khai ứng dụng bằng Docker Image và Docker Compose. Thực hành tạo, cấu hình, và triển khai tài nguyên AWS theo mô hình Infrastructure as Code và container-based deployment. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - TÌm hiểu AWS Backup: + Backup vault + Backup plan + Sử dụng cloudFormation để tạo backup plan 13/10/2025 15/10/2025 https://000013.awsstudygroup.com/ 3 - Thực hành: + Tạo backup plan +Tạo on-demand backup + Tạo backup vaults 13/10/2025 15/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu AWS WAF và AWS privateLink : + ACL + Rules + Rules groups + VPC Endpoint Service + VPC Endpoint + Network Load Balancer 15/10/2025 17/10/2025 https://000026.awsstudygroup.com/ https://000111.awsstudygroup.com/ 5 - Tìm hiểu AWS KMS : + Symetric Key + Asymetric Key -Practice: + Tạo ACLs + Create rules and rules group 17/10/2025 19/10/2025 https://000033.awsstudygroup.com/ 6 - Tìm hiểu sự vận chuyển hàng container cùng với Docker: + Docker là gì + Triển khai chỉ sử dụng Docker Image \u0026lt;br + Triển khai Docker compose và đẩy image 19/10/2025 21/10/2025 https://000015.awsstudygroup.com/ Kết quả đạt được tuần 6: Hoàn thành việc học và thực hành AWS Backup, tạo thành công Backup Vault, Backup Plan, và On-demand Backup thông qua giao diện AWS và CloudFormation template. Thiết lập và thử nghiệm AWS WAF, bao gồm việc tạo ACLs, Rules, và Rule Groups để bảo vệ ứng dụng web. Hiểu rõ cơ chế hoạt động của AWS PrivateLink, triển khai VPC Endpoint Service và VPC Endpoint kết nối qua Network Load Balancer. Nghiên cứu và áp dụng AWS KMS, tạo và quản lý Symmetric và Asymmetric keys để mã hóa dữ liệu. Tạo và triển khai ứng dụng bằng Docker, thực hành build Docker Image, chạy container, triển khai với Docker Compose, và push image lên Docker Hub. Củng cố kiến thức về Cloud Security và Containerization, chuẩn bị nền tảng cho việc triển khai hệ thống thực tế trên môi trường AWS Cloud. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Tìm hiểu những dịch vụ của AWS để tối ưu hiệu năng Những dịch vụ cần thiết cho việc tối ưu hiệu năng như ECS, EKS,CodePipeline, Storage gateway Tìm hiểu về Docker, Kubernetes, và mối quan hệ giữa Docker và kubernetes Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu AWS EKS : + Control Plane(AWS managed) + Workder Nodes(user-managed) + Tất cả thành phần trong EKS :Cluster, Node group, Pod, Deployment/Service 20/10/2025 21/10/2025 https://000126.awsstudygroup.com/1-introduce/ 3 - Thực hành: : + Tạo network:VPC, subnets, internet gateway + Tạo quyền cho control plane + Khởi tạo EKS cluster + Cài đặt addon: vpc-cni, kube-proxy + Tạo quyền cho worker node + Khởi tạo worker node + Cài đặt addon: coredns + Test nginx deployment 21/10/2025 22/10/2025 https://000126.awsstudygroup.com/1-introduce 4 - Tìm hiểu AWS ECS: + Cluster, task denifition, task, service, container agent + ECS launch types + Networking trong ECS + Tích hợp với dịch vụ khác + ECS Auto Scaling 22/10/2025 24/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu AWS Storage Gateway - Thực hành:\n+ Tạo ECS cluster + Cấu hình Docker image + Tạo Task definition + Đăng kí namespace trong Cloud Map 23/10/2025 25/10/2025 https://000016.awsstudygroup.com/1-introduction/ 6 - Tìm hiểu AWS CodePipeline: + Giai đoạn Source: Lấy code từ GitHub, CodeCommit hoặc S3 + Giai đoạn Build: Gọi CodeBuild để biên dịch + Giai đoạn Deploy: Gọi CodeDeploy để triển khai + 25/10/2025 27/10/2025 https://000017.awsstudygroup.com/ Kết quả đạt được tuần 7: Tìm hiểu AWS EKS:\nHiểu rõ kiến trúc EKS bao gồm Control Plane (AWS managed) và Worker Nodes (self-managed). Nắm vững khái niệm Cluster, Node Group, Pod, Deployment, Service. Biết cách kết nối kubectl tới EKS Cluster và quản lý workloads. Thực hành triển khai EKS:\nTạo VPC, Subnets, Internet Gateway, Route Table. Cấp quyền cho EKS Control Plane (IAM Role). Khởi tạo EKS Cluster và cài addon: vpc-cni, kube-proxy. Tạo Node Group cho Worker Node và cài addon coredns. Triển khai thành công Nginx Deployment trên EKS và truy cập qua LoadBalancer. Tìm hiểu AWS ECS:\nHiểu cơ chế hoạt động của ECS Cluster, Task Definition, Service, Container Agent. Phân biệt ECS Launch Type (EC2 / Fargate). Nắm cấu hình mạng (ECS networking modes: bridge, host, awsvpc). Biết cách tích hợp ECS với CloudWatch, Load Balancer và Auto Scaling. Thực hành triển khai ECS:\nTạo ECS Cluster (Fargate). Build và push Docker image lên ECR. Tạo Task Definition và Service chạy container. Đăng ký namespace trong Cloud Map để ECS có thể service discovery. Tìm hiểu cơ bản về AWS Storage Gateway và mô hình hybrid storage. Tìm hiểu AWS CodePipeline:\nHiểu pipeline CI/CD gồm 3 stage: Source → Build → Deploy. Biết cách tích hợp CodePipeline với GitHub, CodeBuild và CodeDeploy. Hiểu quy trình tự động build và deploy ứng dụng Spring Boot hoặc React lên EC2/S3. Soạn file buildspec.yml và appspec.yml mẫu. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;cloudformation:*\u0026#34;,\r\u0026#34;cloudwatch:*\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:AllocateAddress\u0026#34;,\r\u0026#34;ec2:AssociateAddress\u0026#34;,\r\u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;,\r\u0026#34;ec2:AssociateRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;,\r\u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;,\r\u0026#34;ec2:AttachInternetGateway\u0026#34;,\r\u0026#34;ec2:AttachNetworkInterface\u0026#34;,\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:AttachVpnGateway\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;,\r\u0026#34;ec2:CreateClientVpnRoute\u0026#34;,\r\u0026#34;ec2:CreateCustomerGateway\u0026#34;,\r\u0026#34;ec2:CreateDhcpOptions\u0026#34;,\r\u0026#34;ec2:CreateFlowLogs\u0026#34;,\r\u0026#34;ec2:CreateInternetGateway\u0026#34;,\r\u0026#34;ec2:CreateLaunchTemplate\u0026#34;,\r\u0026#34;ec2:CreateNetworkAcl\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterface\u0026#34;,\r\u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:CreateRoute\u0026#34;,\r\u0026#34;ec2:CreateRouteTable\u0026#34;,\r\u0026#34;ec2:CreateSecurityGroup\u0026#34;,\r\u0026#34;ec2:CreateSubnet\u0026#34;,\r\u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateTransitGateway\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:CreateVpc\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpoint\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;,\r\u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;,\r\u0026#34;ec2:CreateVpnConnection\u0026#34;,\r\u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:CreateVpnGateway\u0026#34;,\r\u0026#34;ec2:DeleteCustomerGateway\u0026#34;,\r\u0026#34;ec2:DeleteFlowLogs\u0026#34;,\r\u0026#34;ec2:DeleteInternetGateway\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterface\u0026#34;,\r\u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;,\r\u0026#34;ec2:DeleteRoute\u0026#34;,\r\u0026#34;ec2:DeleteRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteSecurityGroup\u0026#34;,\r\u0026#34;ec2:DeleteSubnet\u0026#34;,\r\u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteTransitGateway\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;,\r\u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:DeleteVpc\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpoints\u0026#34;,\r\u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnection\u0026#34;,\r\u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;,\r\u0026#34;ec2:Describe*\u0026#34;,\r\u0026#34;ec2:DetachInternetGateway\u0026#34;,\r\u0026#34;ec2:DisassociateAddress\u0026#34;,\r\u0026#34;ec2:DisassociateRouteTable\u0026#34;,\r\u0026#34;ec2:GetLaunchTemplateData\u0026#34;,\r\u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;,\r\u0026#34;ec2:ModifyInstanceAttribute\u0026#34;,\r\u0026#34;ec2:ModifySecurityGroupRules\u0026#34;,\r\u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;,\r\u0026#34;ec2:ModifyVpcAttribute\u0026#34;,\r\u0026#34;ec2:ModifyVpcEndpoint\u0026#34;,\r\u0026#34;ec2:ReleaseAddress\u0026#34;,\r\u0026#34;ec2:ReplaceRoute\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;,\r\u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;,\r\u0026#34;ec2:RunInstances\u0026#34;,\r\u0026#34;ec2:StartInstances\u0026#34;,\r\u0026#34;ec2:StopInstances\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;,\r\u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;,\r\u0026#34;iam:AddRoleToInstanceProfile\u0026#34;,\r\u0026#34;iam:AttachRolePolicy\u0026#34;,\r\u0026#34;iam:CreateInstanceProfile\u0026#34;,\r\u0026#34;iam:CreatePolicy\u0026#34;,\r\u0026#34;iam:CreateRole\u0026#34;,\r\u0026#34;iam:DeleteInstanceProfile\u0026#34;,\r\u0026#34;iam:DeletePolicy\u0026#34;,\r\u0026#34;iam:DeleteRole\u0026#34;,\r\u0026#34;iam:DeleteRolePolicy\u0026#34;,\r\u0026#34;iam:DetachRolePolicy\u0026#34;,\r\u0026#34;iam:GetInstanceProfile\u0026#34;,\r\u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;iam:GetRole\u0026#34;,\r\u0026#34;iam:GetRolePolicy\u0026#34;,\r\u0026#34;iam:ListPolicyVersions\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;iam:PutRolePolicy\u0026#34;,\r\u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;,\r\u0026#34;lambda:CreateFunction\u0026#34;,\r\u0026#34;lambda:DeleteFunction\u0026#34;,\r\u0026#34;lambda:DeleteLayerVersion\u0026#34;,\r\u0026#34;lambda:GetFunction\u0026#34;,\r\u0026#34;lambda:GetLayerVersion\u0026#34;,\r\u0026#34;lambda:InvokeFunction\u0026#34;,\r\u0026#34;lambda:PublishLayerVersion\u0026#34;,\r\u0026#34;logs:CreateLogGroup\u0026#34;,\r\u0026#34;logs:DeleteLogGroup\u0026#34;,\r\u0026#34;logs:DescribeLogGroups\u0026#34;,\r\u0026#34;logs:PutRetentionPolicy\u0026#34;,\r\u0026#34;route53:ChangeTagsForResource\u0026#34;,\r\u0026#34;route53:CreateHealthCheck\u0026#34;,\r\u0026#34;route53:CreateHostedZone\u0026#34;,\r\u0026#34;route53:CreateTrafficPolicy\u0026#34;,\r\u0026#34;route53:DeleteHostedZone\u0026#34;,\r\u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;,\r\u0026#34;route53:GetHostedZone\u0026#34;,\r\u0026#34;route53:ListHostedZones\u0026#34;,\r\u0026#34;route53domains:ListDomains\u0026#34;,\r\u0026#34;route53domains:ListOperations\u0026#34;,\r\u0026#34;route53domains:ListTagsForDomain\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:AssociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:CreateResolverRule\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:DeleteResolverRule\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;,\r\u0026#34;route53resolver:DisassociateResolverRule\u0026#34;,\r\u0026#34;route53resolver:GetResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:GetResolverRule\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;,\r\u0026#34;route53resolver:ListResolverEndpoints\u0026#34;,\r\u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;,\r\u0026#34;route53resolver:ListResolverRules\u0026#34;,\r\u0026#34;route53resolver:ListTagsForResource\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;,\r\u0026#34;route53resolver:UpdateResolverRule\u0026#34;,\r\u0026#34;s3:AbortMultipartUpload\u0026#34;,\r\u0026#34;s3:CreateBucket\u0026#34;,\r\u0026#34;s3:DeleteBucket\u0026#34;,\r\u0026#34;s3:DeleteObject\u0026#34;,\r\u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetBucketAcl\u0026#34;,\r\u0026#34;s3:GetBucketOwnershipControls\u0026#34;,\r\u0026#34;s3:GetBucketPolicy\u0026#34;,\r\u0026#34;s3:GetBucketPolicyStatus\u0026#34;,\r\u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;s3:GetObjectVersion\u0026#34;,\r\u0026#34;s3:GetBucketVersioning\u0026#34;,\r\u0026#34;s3:ListAccessPoints\u0026#34;,\r\u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:ListBucketMultipartUploads\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;,\r\u0026#34;s3:ListJobs\u0026#34;,\r\u0026#34;s3:ListMultipartUploadParts\u0026#34;,\r\u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;,\r\u0026#34;s3:ListStorageLensConfigurations\u0026#34;,\r\u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutBucketAcl\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;,\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;secretsmanager:CreateSecret\u0026#34;,\r\u0026#34;secretsmanager:DeleteSecret\u0026#34;,\r\u0026#34;secretsmanager:DescribeSecret\u0026#34;,\r\u0026#34;secretsmanager:GetSecretValue\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;,\r\u0026#34;secretsmanager:PutResourcePolicy\u0026#34;,\r\u0026#34;secretsmanager:TagResource\u0026#34;,\r\u0026#34;secretsmanager:UpdateSecret\u0026#34;,\r\u0026#34;sns:ListTopics\u0026#34;,\r\u0026#34;ssm:DescribeInstanceProperties\u0026#34;,\r\u0026#34;ssm:DescribeSessions\u0026#34;,\r\u0026#34;ssm:GetConnectionStatus\u0026#34;,\r\u0026#34;ssm:GetParameters\u0026#34;,\r\u0026#34;ssm:ListAssociations\u0026#34;,\r\u0026#34;ssm:ResumeSession\u0026#34;,\r\u0026#34;ssm:StartSession\u0026#34;,\r\u0026#34;ssm:TerminateSession\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/",
	"title": "Kiểm tra Gateway Endpoint",
	"tags": [],
	"description": "",
	"content": "Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "HỆ THỐNG DỊCH VỤ ĐƯỜNG SẮT ĐÔ THỊ TRÊN AWS Kiến Trúc Đám Mây An Toàn — Mở Rộng — Tối Ưu Chi Phí Executive Summary Thành phố Hồ Chí Minh đang đối mặt với các thách thức lớn về giao thông, bao gồm tắc nghẽn, ô nhiễm và áp lực dân số đô thị hóa.\nDự án Đường sắt Đô thị được xem là bước đột phá trong việc xây dựng hệ thống giao thông thông minh, bền vững và thân thiện với môi trường.\nBản đề xuất này trình bày một kiến trúc đám mây toàn diện dựa trên AWS, được thiết kế để hỗ trợ các chức năng cốt lõi như:\nĐặt vé điện tử \u0026amp; thanh toán không tiền mặt Quản lý lịch trình và giám sát vận hành Phân tích dữ liệu và tối ưu lưu lượng hành khách Kiến trúc tuân thủ các nguyên tắc serverless, event-driven, và CI/CD automation, bảo đảm:\nHiệu suất và khả năng mở rộng linh hoạt. Bảo mật đầu-cuối đạt tiêu chuẩn doanh nghiệp. Chi phí vận hành tối ưu theo mô hình pay-as-you-go. Key Highlights 100% cloud-native \u0026amp; serverless architecture (AWS Lambda, EventBridge) End-to-end enterprise security (Cognito, WAF, KMS) Fully automated CI/CD \u0026amp; observability (CodePipeline, CloudWatch) Seamless e-ticketing \u0026amp; cashless payment (VNPay, MoMo) Real-time analytics \u0026amp; predictive insights (Athena, QuickSight) 1. Mục Tiêu Dự Án Mục tiêu tổng quát:\nXây dựng hạ tầng kỹ thuật số đáng tin cậy, an toàn, và có khả năng mở rộng cho hệ thống Đường sắt Đô thị TP. Hồ Chí Minh trên nền tảng AWS Cloud.\nMục tiêu cụ thể:\nTriển khai kiến trúc serverless \u0026amp; event-driven sử dụng AWS Lambda và EventBridge. Cung cấp các tính năng đặt vé, thanh toán, xác thực và cập nhật lịch trình thời gian thực. Áp dụng bảo mật đầu-cuối (WAF, Cognito, KMS, Secrets Manager). Tự động hóa CI/CD với CodePipeline, CodeBuild, CodeDeploy. Thiết lập giám sát và tuân thủ qua CloudWatch, CloudTrail. 2. Phạm Vi Dự Án Thành phần Mô tả Địa điểm Tuyến Metro số 1 (Bến Thành – Suối Tiên), TP.HCM Người dùng mục tiêu Hành khách, nhân viên vận hành, quản trị viên Thời gian triển khai 12 năm (bao gồm triển khai \u0026amp; vận hành dài hạn) Giai đoạn 1 Đặt vé, xác thực, lịch trình, thanh toán Giai đoạn mở rộng Phân tích dự đoán, IoT giám sát, tối ưu hành khách 2.1 Functional Requirements ID Requirement Priority FR-01 Users can book tickets and pay online High FR-02 Real-time schedule updates via API High FR-03 Automatic maintenance alerting Medium FR-04 Admin can view passenger analytics Medium FR-05 Multi-language (EN, VN) support Low 2.2 Non-Functional Requirements Availability: ≥ 99.95% uptime (Multi-AZ) Latency: \u0026lt; 300 ms for booking operations Security: Compliance with ISO 27001 \u0026amp; SOC 2 Type II Scalability: Auto scale to 100k concurrent users Cost Efficiency: ≤ $100/month base infrastructure 3. Kiến Trúc AWS Đề Xuất 3.1 Tổng Quan Hệ thống được xây dựng theo mô hình đa lớp (multi-tier), phi máy chủ (serverless), và tự động (automated), đảm bảo khả năng mở rộng động, vận hành tin cậy và bảo mật toàn diện.\nArchitecture Diagram Summary Layer Service Role Frontend CloudFront + S3 Static hosting, caching, HTTPS delivery API Layer API Gateway + Lambda Business logic, event-driven functions Data RDS + S3 + DynamoDB Persistent and analytical data storage Security WAF + Cognito + KMS Authentication, encryption, protection Monitoring CloudWatch + GuardDuty Metrics, alerts, and anomaly detection 3.2 Lớp Mạng \u0026amp; Truy Cập Amazon Route 53: Quản lý DNS, đảm bảo độ sẵn sàng toàn cầu. Amazon CloudFront (CDN): Phân phối nội dung tĩnh và giảm tải backend. AWS WAF: Bảo vệ trước các tấn công DDoS, SQL Injection, XSS. 3.3 Lớp Ứng Dụng \u0026amp; API Amazon API Gateway: Cung cấp các endpoint RESTful bảo mật. AWS Lambda: Xử lý logic nghiệp vụ chính: BookingServiceLambda: Xử lý đặt vé. PaymentLambda: Tích hợp thanh toán VNPay/MoMo. ScheduleLambda: Cập nhật lịch trình. NotificationLambda: Gửi thông báo (SNS, email, SMS). Amazon EventBridge: Tự động điều phối quy trình (payment → invoice → notify). 3.4 Lớp Dữ Liệu \u0026amp; Lưu Trữ Amazon RDS (SQL Server): Lưu trữ dữ liệu người dùng, vé, thanh toán. Amazon S3: Lưu trữ file tĩnh, log, hóa đơn, dữ liệu sao lưu. Tích hợp Lifecycle Policy → S3 Glacier để tiết kiệm chi phí. 3.5 Lớp Bảo Mật \u0026amp; Xác Thực Amazon Cognito: Đăng ký, đăng nhập, MFA, cấp JWT token. AWS Secrets Manager: Lưu trữ và xoay vòng khóa bí mật. AWS KMS: Mã hóa dữ liệu RDS/S3. AWS CloudTrail: Ghi nhật ký và giám sát API, đảm bảo compliance. 3.6 Lớp Giám Sát \u0026amp; Tuân Thủ Amazon CloudWatch: Theo dõi hiệu suất và log Lambda/API. CloudWatch Alarms + SNS: Gửi cảnh báo tự động. CloudTrail: Theo dõi thay đổi hệ thống và hoạt động người dùng. 3.7 Lớp CI/CD \u0026amp; Tự Động Hóa AWS CodePipeline: Tự động build–test–deploy. AWS CodeBuild: Kiểm thử mã backend/frontend mỗi lần commit. AWS CodeDeploy: Triển khai an toàn, không downtime. GitHub Webhook: Tự động kích hoạt pipeline sau commit. Data Flow (Simplified) User -\u0026gt; CloudFront -\u0026gt;API Gateway -\u0026gt; Lambda -\u0026gt; RDS\n|v EventBridge -\u0026gt; SNS/Email Notification\n|v CloudWatch -\u0026gt; Admin Dashboard\n4. Kế Hoạch Triển Khai Giai đoạn Thời gian Hạng mục chính 1 Tuần 1–2 Thiết lập Route 53, CloudFront, API Gateway, Lambda, RDS 2 Tuần 3–4 Phát triển đặt vé, xác thực (Cognito, Lambda, EventBridge) 3 Tuần 5–6 Tích hợp thanh toán, giám sát CloudWatch, cấu hình WAF 4 Tuần 7–8 CI/CD (CodePipeline, CodeBuild, CodeDeploy) 5 Mở rộng Phân tích dữ liệu (Athena, QuickSight) 5. Ngân Sách \u0026amp; Nhân Sự Thành phần Dịch vụ Ước tính (USD/tháng) Mạng \u0026amp; CDN Route 53, CloudFront, WAF $15 Backend Serverless Lambda, API Gateway, EventBridge $20 Dữ liệu \u0026amp; Lưu Trữ RDS, S3 $35 CI/CD CodePipeline, CodeBuild, CodeDeploy $10 Bảo mật \u0026amp; Giám sát CloudWatch, CloudTrail, Cognito, KMS $15 Tổng cộng — ≈ $95–100/tháng Nhân sự:\nCloud Architect Backend Developer (Lambda, API Gateway) Frontend Developer (React, S3/CloudFront) DevOps Engineer (CI/CD \u0026amp; Monitoring) Metro Operations Specialist 6. Kết Quả Kỳ Vọng Nền tảng vận hành an toàn, hiện đại, dựa trên AWS Cloud. Thanh toán không tiền mặt và xác nhận vé tự động. Hạ tầng mở rộng linh hoạt, sẵn sàng cho tích hợp IoT. Minh bạch vận hành qua dashboard phân tích dữ liệu. Chi phí tối ưu nhờ mô hình trả theo mức sử dụng. 7. Rủi Ro \u0026amp; Giải Pháp Rủi ro Giải pháp Gián đoạn mạng AWS Thiết lập Multi-AZ, failover tự động Quá tải Lambda Bật autoscaling và giới hạn timeout Tấn công bảo mật Sử dụng WAF, IAM least privilege, KMS Sai lệch dữ liệu Tự động sao lưu và khôi phục RDS Lỗi triển khai CI/CD rollback và CloudFormation drift detection 7.1 Risk Classification Matrix Risk Likelihood Impact Mitigation Network outage Medium High Multi-AZ + Failover API overload High Medium Lambda concurrency + autoscaling Data breach Low High KMS encryption + WAF CI/CD failure Medium Low Rollback + versioning 8. Tuân Thủ \u0026amp; Bảo Mật Compliance: ISO 27001, GDPR-ready, SOC2 Type II Encryption: AES-256 (KMS-managed) IAM Policies: Principle of Least Privilege Monitoring: Continuous Audit với CloudTrail \u0026amp; GuardDuty 9. Kết Luận Hệ thống Đường Sắt Đô Thị Trên AWS là nền tảng chiến lược giúp chuyển đổi số ngành giao thông công cộng tại TP.HCM.\nVới kiến trúc serverless – event-driven – CI/CD automation, giải pháp này đáp ứng các yêu cầu hiện đại về bảo mật, hiệu suất và chi phí.\nĐây không chỉ là dự án kỹ thuật, mà còn là bước tiến hướng tới thành phố thông minh trong tương lai.\n10. Success Metrics KPI Target Measurement Tool System Availability ≥ 99.95% CloudWatch uptime metrics API Latency \u0026lt; 300 ms CloudWatch logs Ticket Processing 10,000+/day Lambda invocation count Cost Optimization \u0026lt; $100/month AWS Cost Explorer Security Compliance 100% GuardDuty \u0026amp; IAM Audit Appendix A — AWS Services Summary Category Services Used Purpose Networking Route 53, CloudFront DNS, CDN, HTTPS Compute Lambda Serverless compute API API Gateway REST API endpoints Database RDS (SQL Server) Transactional data Storage S3 + Glacier File storage \u0026amp; archival Security Cognito, WAF, KMS, Secrets Manager Authentication \u0026amp; protection DevOps CodePipeline, CodeBuild, CodeDeploy CI/CD automation Monitoring CloudWatch, CloudTrail, GuardDuty Observability \u0026amp; compliance 🖼️ Hình minh họa:\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/",
	"title": "Tạo một S3 Interface endpoint",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Các dịch vụ AWS vươn lên tầm cao mới trong Prime Day 2025: các số liệu và cột mốc chính Prime Day 2025 lập kỷ lục mới nhờ sức mạnh công nghệ của AWS. Các trung tâm hoàn tất đơn hàng với hơn 7.000 robot ASRS được vận hành bởi AWS Outposts, xử lý hơn 524 triệu lệnh và đạt đỉnh 8 triệu lệnh/giờ (tăng 160% so với 2024). Nhờ hạ tầng AWS kết hợp kinh nghiệm bán lẻ của Amazon, khách hàng dễ dàng tìm ưu đãi, nhận thông tin sản phẩm nhanh chóng và được giao hàng trong ngày hoặc hôm sau.\nBlog 2 - AWS được công nhận là Nhà lãnh đạo trong báo cáo Gartner Magic Quadrant 2025 về Nền tảng Ứng dụng Cloud-Native và Quản lý Container Trong kỷ nguyên điện toán đám mây và trí tuệ nhân tạo bùng nổ, doanh nghiệp liên tục tìm kiếm nền tảng công nghệ giúp họ đổi mới nhanh hơn, vận hành linh hoạt hơn và tối ưu chi phí tốt hơn. Với hệ sinh thái dịch vụ toàn diện, AWS không chỉ đồng hành cùng hàng triệu khách hàng toàn cầu trong hành trình chuyển đổi số, mà còn tiếp tục khẳng định vị thế tiên phong khi được Gartner công nhận là Nhà lãnh đạo (Leader) trong nhiều hạng mục quan trọng của Magic Quadrant 2025.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/",
	"title": "Kiểm tra Interface Endpoint",
	"tags": [],
	"description": "",
	"content": "Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-s3-vpc/",
	"title": "Truy cập S3 từ VPC",
	"tags": [],
	"description": "",
	"content": "Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/",
	"title": "Mô phỏng On-premises DNS ",
	"tags": [],
	"description": "",
	"content": "AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-s3-onprem/",
	"title": "Truy cập S3 từ môi trường truyền thống",
	"tags": [],
	"description": "",
	"content": "Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-policy/",
	"title": "VPC Endpoint Policies",
	"tags": [],
	"description": "",
	"content": "Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. {\r\u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;,\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;,\r\u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34;\r],\r\u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r} Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nĐảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]